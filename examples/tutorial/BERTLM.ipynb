{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "urban-divorce",
   "metadata": {},
   "source": [
    "# BERTLM\n",
    "\n",
    "可用的中文预训练参数：[`bert-base`](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip),[`roberta-wwm-ext-base`](https://drive.google.com/uc?export=download&id=1jMAKIJmPn7kADgD3yQZhpsqM-IRM1qZt),[`roberta-wwm-ext-large`](https://drive.google.com/uc?export=download&id=1dtad0FFzG11CBsawu8hvwwzU2R0FDI94),[`macbert-base`](https://drive.google.com/uc?export=download&id=1aV69OhYzIwj_hn-kO1RiBa-m8QAusQ5b),[`macbert-large`](https://drive.google.com/uc?export=download&id=1lWYxnk1EqTA2Q20_IShxBrCPc5VSDCkT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rotary-academy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.5.12\n"
     ]
    }
   ],
   "source": [
    "import uf\n",
    "\n",
    "print(uf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-symbol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uf.BERTLM(\n",
      "    config_file=\"../../ref/bert_config.json\",\n",
      "    vocab_file=\"../../ref/vocab.txt\",\n",
      "    max_seq_length=128,\n",
      "    init_checkpoint=None,\n",
      "    output_dir=None,\n",
      "    gpu_ids=None,\n",
      "    drop_pooler=False,\n",
      "    do_sample_next_sentence=True,\n",
      "    max_predictions_per_seq=20,\n",
      "    masked_lm_prob=0.15,\n",
      "    short_seq_prob=0.1,\n",
      "    do_whole_word_mask=False,\n",
      "    do_lower_case=True,\n",
      "    truncate_method=\"LIFO\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = uf.BERTLM(\"../../ref/bert_config.json\", \"../../ref/vocab.txt\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "drawn-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[\"天亮以前说再见，\", \"笑着泪流满面，\", \"去迎接应该你的，\", \"更好的明天。\"],    # 每一条样本是一个doc，doc内可以由多个句子组成\n",
    "     \"他想知道那是谁, 为何总沉默寡言, 人群中也算抢眼, 抢眼的孤独难免\",              # 也可以是一个完整的文段\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-fault",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excellent-religion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:235: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  query_layer = tf.layers.dense(\n",
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:245: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  key_layer = tf.layers.dense(\n",
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:255: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  value_layer = tf.layers.dense(\n",
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:379: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  attention_output = tf.layers.dense(\n",
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:391: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  intermediate_output = tf.layers.dense(\n",
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:401: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  layer_output = tf.layers.dense(\n",
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:102: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.pooled_output = tf.layers.dense(\n",
      "c:\\Users\\Luv_d\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uf-2.5.12-py3.9.egg\\uf\\apps\\bert\\bert.py:463: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  input_tensor = tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Build graph with 308,647,326 parameters (among which 102,882,442 are trainable)\n",
      "INFO:tensorflow:Running local_init_op\n",
      "INFO:tensorflow:Done running local_init_op\n",
      "INFO:tensorflow:Running training on 2 samples (step 0 -> 20)\n",
      "INFO:tensorflow:step 1, MLM accuracy 0.0000, NSP accuracy 0.5000, MLM loss 3.499341, NSP loss 0.655330, 0.15 steps/sec, 0.29 examples/sec\n",
      "INFO:tensorflow:step 2, MLM accuracy 0.2143, NSP accuracy 0.5000, MLM loss 2.985084, NSP loss 0.675953, 0.35 steps/sec, 0.71 examples/sec\n",
      "INFO:tensorflow:step 3, MLM accuracy 0.5714, NSP accuracy 0.5000, MLM loss 2.569047, NSP loss 0.658974, 0.67 steps/sec, 1.34 examples/sec\n",
      "INFO:tensorflow:step 4, MLM accuracy 0.6429, NSP accuracy 1.0000, MLM loss 2.312638, NSP loss 0.565874, 0.65 steps/sec, 1.30 examples/sec\n",
      "INFO:tensorflow:step 5, MLM accuracy 0.8571, NSP accuracy 1.0000, MLM loss 2.080005, NSP loss 0.504693, 0.60 steps/sec, 1.21 examples/sec\n",
      "INFO:tensorflow:step 6, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 1.845879, NSP loss 0.434266, 0.58 steps/sec, 1.16 examples/sec\n",
      "INFO:tensorflow:step 7, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 1.669613, NSP loss 0.333697, 0.54 steps/sec, 1.07 examples/sec\n",
      "INFO:tensorflow:step 8, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 1.461325, NSP loss 0.249344, 0.60 steps/sec, 1.19 examples/sec\n",
      "INFO:tensorflow:step 9, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 1.316961, NSP loss 0.208784, 0.61 steps/sec, 1.22 examples/sec\n",
      "INFO:tensorflow:step 10, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 1.169598, NSP loss 0.127614, 0.62 steps/sec, 1.23 examples/sec\n",
      "INFO:tensorflow:step 11, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 1.048312, NSP loss 0.077173, 0.56 steps/sec, 1.12 examples/sec\n",
      "INFO:tensorflow:step 12, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.948024, NSP loss 0.093149, 0.58 steps/sec, 1.17 examples/sec\n",
      "INFO:tensorflow:step 13, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.872769, NSP loss 0.067999, 0.62 steps/sec, 1.25 examples/sec\n",
      "INFO:tensorflow:step 14, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.810208, NSP loss 0.042315, 0.55 steps/sec, 1.11 examples/sec\n",
      "INFO:tensorflow:step 15, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.732139, NSP loss 0.048923, 0.61 steps/sec, 1.22 examples/sec\n",
      "INFO:tensorflow:step 16, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.689348, NSP loss 0.032856, 0.61 steps/sec, 1.23 examples/sec\n",
      "INFO:tensorflow:step 17, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.647938, NSP loss 0.035998, 0.60 steps/sec, 1.21 examples/sec\n",
      "INFO:tensorflow:step 18, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.600404, NSP loss 0.035110, 0.65 steps/sec, 1.30 examples/sec\n",
      "INFO:tensorflow:step 19, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.574783, NSP loss 0.029402, 0.68 steps/sec, 1.35 examples/sec\n",
      "INFO:tensorflow:step 20, MLM accuracy 1.0000, NSP accuracy 1.0000, MLM loss 0.562205, NSP loss 0.033157, 0.68 steps/sec, 1.36 examples/sec\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, total_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-hundred",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opposite-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running inference on 1 samples\n",
      "INFO:tensorflow:process 100.0%, 1.14 examples/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlm_preds': [['的']],\n",
       " 'mlm_probs': [[0.006000343710184097]],\n",
       " 'nsp_preds': [1],\n",
       " 'nsp_probs': array([[0.00253978, 0.9974602 ]], dtype=float32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokenized = [[\"天\", \"亮\", \"以\", \"[MASK]\", \"说\", \"再\", \"见\"]]    # 可以手动赋予Mask预测 (与训练阶段采样不同，因此此case预测错误正常)\n",
    "model.predict(X_tokenized=X_tokenized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "265fd6f62f200408acbbeae0248f34bed9f93569a643842b7a25d2cd76cae5e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
